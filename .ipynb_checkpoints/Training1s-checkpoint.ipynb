{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import manage_data as md\n",
    "import preprocessing as pp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, filename='cm'):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=20, fontstyle='oblique')\n",
    "    #plt.colorbar()\n",
    "    ax = plt.subplot()\n",
    "    tick_marks = np.arange(2)\n",
    "    labels = ['Sticking', 'Fine']\n",
    "    plt.xticks(tick_marks, labels, rotation=45, fontsize=20)\n",
    "    plt.yticks(tick_marks, labels, fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n",
    "    width, height = cm.shape\n",
    "    for x in xrange(width):\n",
    "        xx = np.round(x, 2)\n",
    "        for y in xrange(height):\n",
    "            yy = np.round(y, 2)\n",
    "            valeur = str(int(np.round(100 * cm[x][y],0)))+'%'\n",
    "            ax.annotate(valeur, xy=(y, x), \n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        size=30)\n",
    "    plt.savefig('./images/cm_one/' + filename + '.png')\n",
    "    #plt.text(0.1, 0.1,'Caption')\n",
    "\n",
    "def concat_df(coil_list, filename='peaks.h5'):\n",
    "    big_df = md.importPeak(coil_list[0], filename).dropna()\n",
    "    for coil in coil_list[1:]:\n",
    "        df = md.importPeak(coil, filename).dropna()\n",
    "        big_df = pd.concat([big_df, df], ignore_index=True)\n",
    "    return big_df\n",
    "\n",
    "def create_DB(df):\n",
    "    feature_col = ['Ximf0', 'Ximf1', 'Ximf2', 'Yimf0', 'Yimf1', 'Yimf2', 'thickness', 'speed']\n",
    "    X = df[feature_col].values\n",
    "    Y = df[['sticking']]\n",
    "    Y = np.array(Y.sticking.values[:], dtype=bool)\n",
    "    return X, Y\n",
    "\n",
    "def random_sample(coil_list):\n",
    "    df = concat_df(coil_list)\n",
    "    sticking_index = list(df[df.sticking==True].index)\n",
    "    non_sticking_index = list(df[df.sticking==False].index)\n",
    "    group_of_items = non_sticking_index               # a sequence or set will work here.\n",
    "    num_to_select = len(df[df.sticking==True])        # set the number to select here.\n",
    "    list_of_random_items = random.sample(group_of_items, num_to_select)\n",
    "    list_of_random_items\n",
    "    ind = sticking_index+list_of_random_items\n",
    "    return df.loc[ind]\n",
    "\n",
    "def random_coils_selection(coil_list, ratio=0.5):\n",
    "    aux  = list(coil_list)\n",
    "    random.shuffle(aux)\n",
    "    n = int(ratio * len(aux))+1\n",
    "    return aux[:n], aux[n:]\n",
    "\n",
    "def result_per_coil(coil_list, estimator):\n",
    "    sum_true = []\n",
    "    sum_predict = []\n",
    "    for coil in coil_list:\n",
    "        df_test = concat_df([coil])\n",
    "        X_test, Y_true = create_DB(df_test)\n",
    "        Y_predict = estimator.predict(X_test)\n",
    "        sum_true.append(sum(Y_true))\n",
    "        sum_predict.append(sum(Y_predict))\n",
    "    d = {'truth':sum_true, 'prediction':sum_predict}\n",
    "    result = pd.DataFrame(d, index=coil_list)\n",
    "    return result, np.array(sum_true), np.array(sum_predict)\n",
    "\n",
    "def sticking_coils_finder(coil_list):\n",
    "    sum_true = []\n",
    "    coils = []\n",
    "    for coil in coil_list:\n",
    "        df_test = concat_df([coil])\n",
    "        X_test, Y_true = create_DB(df_test)\n",
    "        sum_true.append(sum(Y_true))\n",
    "    for coil, sumtrue in zip(coil_list, sum_true):\n",
    "        if sumtrue>0:\n",
    "            coils.append(coil)\n",
    "    fine_coils = sorted(list(set(coil_list) - set(coils)))\n",
    "    return sorted(coils), sorted(fine_coils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peakDB = 'peaks_14t_10_60Hz.h5'\n",
    "all_coils = list( set(range(88)) - set([49, 31]) )\n",
    "sticking_coils, fine_coils = sticking_coils_finder(all_coils)\n",
    "k = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nSticking = 26\n",
    "nFine = 33\n",
    "nIter = 37\n",
    "threshold = 2\n",
    "cm = np.zeros([nIter, 2, 2])\n",
    "for start in range(nIter):\n",
    "    stop = start+nSticking\n",
    "    startf = start\n",
    "    stopf = startf+nFine\n",
    "    l1 = sticking_coils[start: stop]+sticking_coils[0: stop-38]\n",
    "    l2 = fine_coils[startf: stopf]+fine_coils[0: stopf-48]\n",
    "    learning_coils = sorted(l1+l2)\n",
    "    testing_coils = sorted(list(set(all_coils)-set(learning_coils)))\n",
    "    df_total_train = concat_df(learning_coils, peakDB)\n",
    "    df_total_test = concat_df(testing_coils, peakDB)\n",
    "    X_train, Y_train = create_DB(df_total_train)\n",
    "    X_test, Y_true = create_DB(df_total_test)\n",
    "    clf = tree.DecisionTreeClassifier(\n",
    "        criterion='gini', \n",
    "        max_depth=8,\n",
    "        class_weight={True: 3, False: 1}\n",
    "    )\n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    result, sumtrue, sumpredict = result_per_coil(testing_coils, clf)\n",
    "    ytrue = np.greater(sumtrue, 0)\n",
    "    ypredict = np.greater(sumpredict, threshold)\n",
    "    cm0 = metrics.confusion_matrix(ytrue, ypredict, labels=[True, False])\n",
    "    cm_normalized = cm0.astype('float') / cm0.sum(axis=1)[:, np.newaxis]\n",
    "    cm[start,:,:] = cm_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    cm.mean(0), \n",
    "    title='Cross validation confusion matrix', \n",
    "    filename='Cross validation confusion matrix'\n",
    ")\n",
    "plot_confusion_matrix(\n",
    "    cm.std(0), \n",
    "    title='Confusion matrix STD', \n",
    "    filename='Confusion matrix STD'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually chosen learning coils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_coils = [0, 1, 4, 5, 7, 10, 11, 12, 13, 14, 15, 15, 17, 18, 20, 24, 25, 26, 28, 29, 30, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 50, 51, 52, 53, 54, 56, 57, 59, 62, 63, 65, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 81, 82, 84, 85, 87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_sticking_coil = sorted([7, 15, 28, 50, 78, 79, 81, 82, 62, 74])\n",
    "big_sticking_error = [13, 38, 40, 65] + [29, 34, 37, 44, 52, 53, 56] + [4, 17, 20]\n",
    "learning_fine_coils = sorted([10, 24, 25, 30, 33, 42, 46, 47, 85])\n",
    "big_fine_error = [36, 77]+[1, 5, 11, 15, 45, 57, 75] + [0, 12, 14, 18, 26]\n",
    "big_fine_error += [35, 39, 41, 51, 54, 59, 63, 68, 69, 70, 73, 76, 84, 87]\n",
    "learning_coils = learning_sticking_coil + learning_fine_coils\n",
    "learning_coils += big_fine_error\n",
    "learning_coils += big_sticking_error\n",
    "testing_coils = list(set(range(88)) - set(learning_coils) - set({31, 49}))\n",
    "n = len(learning_coils)+len(testing_coils)\n",
    "nl = int(np.round(len(learning_coils)*100./n,0))\n",
    "nt = int(np.round(len(testing_coils)*100./n,0))\n",
    "print(str(nl)+'% learning coils: '+str(len(learning_coils)))\n",
    "print(str(nt)+'% testing coils: '+str(len(testing_coils)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sorted(learning_coils))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly chosen learning coil with good results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0/81 with no missed coil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_coils = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 17, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 42, 44, 45, 47, 48, 50, 51, 52, 54, 58, 59, 60, 62, 63, 64, 65, 69, 71, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 84]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24/62 with depth=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_coils = [0, 1, 2, 5, 6, 7, 9, 10, 11, 13, 14, 16, 18, 22, 23, 24, 25, 27, 29, 30, 32, 33, 34, 35, 37, 38, 40, 43, 44, 45, 46, 50, 53, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25/71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_coils = [2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 38, 41, 44, 46, 47, 48, 51, 52, 53, 56, 57, 58, 60, 62, 63, 65, 66, 68, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19/67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_coils = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 15, 17, 19, 23, 25, 26, 29, 30, 33, 35, 36, 37, 38, 39, 40, 41, 42, 44, 45, 46, 48, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 73, 74, 75, 77, 78, 80, 81, 83, 84, 85, 87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20/73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_coils = [0, 4, 5, 7, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 23, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 46, 50, 51, 53, 54, 55, 56, 57, 58, 60, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 82, 83, 84, 87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly chosen learning coil with worst results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 45/57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_coils = [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 25, 26, 29, 32, 34, 35, 36, 39, 40, 41, 42, 43, 44, 46, 47, 50, 51, 52, 54, 56, 57, 58, 59, 61, 62, 63, 64, 66, 67, 68, 70, 71, 72, 74, 78, 79, 83, 84, 85, 86]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning coils summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(learning_coils)\n",
    "nSticking = len(sticking_coils_finder(learning_coils))\n",
    "n = len(learning_coils)\n",
    "stickingPart = 100*nSticking/n\n",
    "print(stickingPart)\n",
    "intRatio = 70\n",
    "graph_title_suffix = '\\n '+str(intRatio)+'/'+str(100-intRatio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing coils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_coils = sorted(list(set(all_coils) - set(learning_coils)))\n",
    "nSticking = len(sticking_coils_finder(testing_coils))\n",
    "n = len(learning_coils)\n",
    "stickingPart = 100*nSticking/n\n",
    "print(stickingPart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random selection with given ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = 0.70\n",
    "learning_coils, testing_coils = random_coils_selection(all_coils, ratio=ratio)\n",
    "n = len(learning_coils)+len(testing_coils)\n",
    "nl = int(np.round(len(learning_coils)*100./n,0))\n",
    "nt = int(np.round(len(testing_coils)*100./n,0))\n",
    "print(str(nl)+'% learning coils: '+str(len(learning_coils)))\n",
    "print(str(nt)+'% testing coils: '+str(len(testing_coils)))\n",
    "k += 1\n",
    "print(k)\n",
    "intRatio = int(100*ratio)\n",
    "graph_title_suffix = '\\n '+str(intRatio)+'/'+str(100-intRatio)\n",
    "print(graph_title_suffix)\n",
    "nSticking = len(sticking_coils_finder(learning_coils))\n",
    "n = len(learning_coils)\n",
    "stickingPart = 100*nSticking/n\n",
    "print(stickingPart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_total = concat_df(all_coils, peakDB)\n",
    "df_total_train = concat_df(learning_coils, peakDB)\n",
    "df_total_test = concat_df(testing_coils, peakDB)\n",
    "df_total_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = create_DB(df_total_train)\n",
    "X_test, Y_true = create_DB(df_total_test)\n",
    "clf = tree.DecisionTreeClassifier(max_depth=9)\n",
    "clf = clf.fit(X_train, Y_train)\n",
    "tree.export_graphviz(clf, out_file='tree.dot')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result per 1s slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_predict = clf.predict(X_test)\n",
    "cm = metrics.confusion_matrix(Y_true, Y_predict, labels=[True, False])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_title = 'Confusion matrix for testing slices'+graph_title_suffix+' Decision Tree'\n",
    "plot_confusion_matrix(cm_normalized, title=cm_title, filename='dt_slices_rand'+str(k))\n",
    "print(cm)\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show learning DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On coils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "suffix = 'threshold='+str(threshold)\n",
    "result_DB, sumtrue, sumpredict = result_per_coil(learning_coils, clf)\n",
    "ytrue = np.greater(sumtrue, 0)\n",
    "ypredict = np.greater(sumpredict, threshold)\n",
    "cm = metrics.confusion_matrix(ytrue, ypredict, labels=[True, False])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plot_confusion_matrix(\n",
    "                    cm_normalized, \n",
    "                    'Confusion matrix for learning coils \\n Decision Tree, '+suffix,\n",
    "                    filename='dt_db_coils_rand'+str(k)\n",
    "                    )\n",
    "print(cm)\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On 1s slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_predict = clf.predict(X_train)\n",
    "cm = metrics.confusion_matrix(Y_train, Y_predict, labels=[True, False])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plot_confusion_matrix(\n",
    "                        cm_normalized, \n",
    "                        'Confusion matrix for learning slices \\n Decision Tree',\n",
    "                        filename='dt_db_slices_rand'+str(k)\n",
    "                        )\n",
    "print(cm)\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result per coil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result, sumtrue, sumpredict = result_per_coil(testing_coils, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "suffix = ' Decision Tree threshold='+str(threshold)\n",
    "ytrue = np.greater(sumtrue, 0)\n",
    "ypredict = np.greater(sumpredict, threshold)\n",
    "cm = metrics.confusion_matrix(ytrue, ypredict, labels=[True, False])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_title = 'Confusion matrix for testing coils'+graph_title_suffix+suffix\n",
    "plot_confusion_matrix(cm_normalized, title=cm_title, filename='dt_coils_rand'+str(k))\n",
    "print(cm)\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sticking detection failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False fine (missed coils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selection = result[(result.truth>0) & (result.prediction<threshold+1)]\n",
    "l = sorted(list(selection.index))\n",
    "print(selection)\n",
    "print(l)\n",
    "print(len(l))\n",
    "print(selection.prediction.mean())\n",
    "print(selection.truth.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False sticking (coils that should not have been inspected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selection = result[(result.truth==0) & (result.prediction>threshold)]\n",
    "l2 = sorted(list(selection.index))\n",
    "print(selection)\n",
    "print(l2)\n",
    "print(len(l2))\n",
    "print(selection.prediction.mean())\n",
    "np.abs(sumtrue-sumpredict).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_coils_1, testing_coils_1 = sorted(learning_coils), sorted(testing_coils)\n",
    "print(learning_coils_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this formatter will label the colorbar with the correct target names\n",
    "#formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])\n",
    "plt.scatter(df_total.Ximf2, df_total.Yimf2, df_total.sticking, color=[\"b\", \"r\"])\n",
    "#plt.colorbar(ticks=[0, 1, 2], format=formatter)\n",
    "#plt.xlabel(iris.feature_names[x_index])\n",
    "#plt.ylabel(iris.feature_names[y_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ytrue_old = np.ones(44).astype(bool)\n",
    "ytrue_old[12:] = False\n",
    "ytest_old = np.ones(44).astype(bool)\n",
    "ytest_old[12:] = False\n",
    "ytest_old[:3] = False\n",
    "ytest_old[-17:] = True\n",
    "sum(ytrue_old)\n",
    "sum(ytest_old)\n",
    "cm = metrics.confusion_matrix(ytrue_old, ytest_old, labels=[True, False])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plot_confusion_matrix(\n",
    "                        cm_normalized, \n",
    "                        'Confusion matrix of previous results \\n 44 chosen coils',\n",
    "                        filename='cm_old'\n",
    "                        )\n",
    "print(cm)\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot sticking and prediction per coil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coil = l[0] #testing_coils[13]\n",
    "df_raw = md.import_data(coil)\n",
    "df_peak = md.importPeak(coil)\n",
    "df_one_coil = concat_df([coil])\n",
    "X_coil, Y_coil = create_DB(df_one_coil)\n",
    "Y_pred_coil = clf.predict(X_coil)\n",
    "df_one_coil['prediction'] = Y_pred_coil\n",
    "x = (df_one_coil.time_begin.values + df_one_coil.time_end.values)/2.\n",
    "plt.title('Coil '+str(coil))\n",
    "plt.bar(x, df_one_coil.sticking.values,4)\n",
    "plt.bar(x, 1./2*df_one_coil.prediction.values,4,color='g')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Sticking [True/False]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selection = result[(result.truth>0) & (result.prediction<threshold+1)]\n",
    "l = sorted(list(selection.index))\n",
    "print(selection)\n",
    "print(l)\n",
    "print(len(l))\n",
    "print(selection.prediction.mean())\n",
    "print(selection.truth.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit_transform(X_train)\n",
    "k_means = cluster.KMeans(n_clusters=2)\n",
    "k_means.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axeX = 0\n",
    "axeY = axeX + 3\n",
    "fig = plt.figure(1)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X_train[:, axeX], X_train[:, axeY], c=k_means.labels_, color=['b', 'r'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(2)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(X_train[:, axeX], X_train[:, axeY], c=Y_train.astype(int), color=['b', 'r'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# K-means result per 4s slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_predict = k_means.predict(X_test)\n",
    "cm = metrics.confusion_matrix(Y_true, Y_predict, labels=[True, False])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_title = 'Confusion matrix for testing slices'+graph_title_suffix+' K-Means'\n",
    "plot_confusion_matrix(\n",
    "    cm_normalized, \n",
    "    title=cm_title, \n",
    "    filename='kmeans_slices_rand'+str(k)\n",
    ")\n",
    "print(cm)\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result, sumtrue, sumpredict = result_per_coil(testing_coils, estimator=k_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "ytrue = np.greater(sumtrue, 0)\n",
    "ypredict = np.greater(sumpredict, threshold)\n",
    "cm = metrics.confusion_matrix(ytrue, ypredict, labels=[True, False])\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "cm_title = 'Confusion matrix for testing coils'+graph_title_suffix+' K-Means'\n",
    "plot_confusion_matrix(\n",
    "    cm_normalized, \n",
    "    title=cm_title, \n",
    "    filename='kmeans_coils_rand'+str(k)\n",
    ")\n",
    "print(cm)\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means sticking detection failure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selection = result[(result.truth>0) & (result.prediction<threshold+1)]\n",
    "lkmeans = sorted(list(selection.index))\n",
    "print(selection)\n",
    "print(lkmeans)\n",
    "print(len(lkmeans))\n",
    "print(selection.prediction.mean())\n",
    "print(selection.truth.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selection = result[(result.truth==0) & (result.prediction>threshold)]\n",
    "lkmeans2 = sorted(list(selection.index))\n",
    "print(selection)\n",
    "print(lkmeans2)\n",
    "print(len(lkmeans2))\n",
    "print(selection.prediction.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coil = 6 #testing_coils[13]\n",
    "df_raw = md.import_data(coil)\n",
    "df_peak = md.importPeak(coil)\n",
    "df_one_coil = concat_df([coil])\n",
    "X_coil, Y_coil = create_DB(df_one_coil)\n",
    "Y_pred_coil = k_means.predict(X_coil)\n",
    "df_one_coil['prediction'] = Y_pred_coil\n",
    "x = (df_one_coil.time_begin.values + df_one_coil.time_end.values)/2.\n",
    "plt.title('Coil '+str(coil))\n",
    "plt.bar(x, df_one_coil.sticking.values,4)\n",
    "plt.bar(x, 1./2*df_one_coil.prediction.values,4,color='g')\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Sticking [True/False]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_coils==[12, 13, 16, 18, 19, 21, 30, 40, 41, 43, 46, 53, 55, 56, 57, 61, 66, 67, 68, 70, 77, 79, 85, 86, 87]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Average CM for random selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratio = 0.70\n",
    "threshold = 0\n",
    "nIter = 5\n",
    "cm = np.zeros([nIter, 2, 2])\n",
    "for randomSeletion in range(nIter):\n",
    "    learning_coils, testing_coils = random_coils_selection(all_coils, ratio=ratio)\n",
    "    df_total_train = concat_df(learning_coils, 'peak_1s_slice.h5')\n",
    "    df_total_test = concat_df(testing_coils, 'peak_1s_slice.h5')\n",
    "    X_train, Y_train = create_DB(df_total_train)\n",
    "    X_test, Y_true = create_DB(df_total_test)\n",
    "    clf = tree.DecisionTreeClassifier(\n",
    "        criterion='gini', \n",
    "        max_depth=9,\n",
    "        class_weight={True: 4, False: 1}\n",
    "    )\n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    result, sumtrue, sumpredict = result_per_coil(testing_coils, clf)\n",
    "    ytrue = np.greater(sumtrue, 0)\n",
    "    ypredict = np.greater(sumpredict, threshold)\n",
    "    cm0 = metrics.confusion_matrix(ytrue, ypredict, labels=[True, False])\n",
    "    cm_normalized = cm0.astype('float') / cm0.sum(axis=1)[:, np.newaxis]\n",
    "    cm[randomSeletion,:,:] = cm_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    cm.mean(0), \n",
    "    title='Average confusion matrix', \n",
    "    filename='Average confusion matrix'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    cm.std(0), \n",
    "    title='Confusion matrix STD', \n",
    "    filename='STD confusion matrix'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm.max(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
